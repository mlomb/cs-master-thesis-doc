@article{nnue:2018,
  title={NNUE: Efficiently Updatable Neural-Network-based Evaluation Functions for Computer Shogi},
  author={Yu Nasu},
  year={2018},
  journal={Ziosoft Computer Shogi Club},
  url={https://www.apply.computer-shogi.org/wcsc28/appeal/the_end_of_genesis_T.N.K.evolution_turbo_type_D/nnue.pdf}
}

@misc{nnue-pytorch,
  title={nnue.md},
  url={https://github.com/official-stockfish/nnue-pytorch/blob/master/docs/nnue.md},
  journal={GitHub},
  author={Official Stockfish}
}

@article{deepblue:2002,
  title={Deep Blue},
  journal={Artificial Intelligence},
  year={2002},
  doi={https://doi.org/10.1016/S0004-3702(01)00129-1},
  url={https://www.sciencedirect.com/science/article/pii/S0004370201001291},
  author={Murray Campbell and A.Joseph Hoane and Feng-hsiung Hsu},
  keywords={Computer chess, Game tree search, Parallel search, Selective search, Search extensions, Evaluation function},
  abstract={Deep Blue is the chess machine that defeated then-reigning World Chess Champion Garry Kasparov in a six-game match in 1997. There were a number of factors that contributed to this success, including: •a single-chip chess search engine,•a massively parallel system with multiple levels of parallelism,•a strong emphasis on search extensions,•a complex evaluation function, and•effective use of a Grandmaster game database. This paper describes the Deep Blue system, and gives some of the rationale that went into the design decisions behind Deep Blue.}
}

@article{alphagozero:2017,
  title={Mastering the game of Go without human knowledge},
  author={David Silver and Julian Schrittwieser and Karen Simonyan and Ioannis Antonoglou and Aja Huang and Arthur Guez and Thomas Hubert and Lucas baker and Matthew Lai and Adrian Bolton and Yutian Chen and Timothy P. Lillicrap and Fan Hui and L. Sifre and George van den Driessche and Thore Graepel and Demis Hassabis},
  journal={Nature},
  year={2017},
  url={https://api.semanticscholar.org/CorpusID:205261034}
}

@misc{alphazero:2017,
  title={Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm}, 
  author={David Silver and Thomas Hubert and Julian Schrittwieser and Ioannis Antonoglou and Matthew Lai and Arthur Guez and Marc Lanctot and Laurent Sifre and Dharshan Kumaran and Thore Graepel and Timothy Lillicrap and Karen Simonyan and Demis Hassabis},
  year={2017},
  eprint={1712.01815},
  archivePrefix={arXiv}
}

@article{alphazero:2018,
  author={David Silver  and Thomas Hubert  and Julian Schrittwieser  and Ioannis Antonoglou  and Matthew Lai  and Arthur Guez  and Marc Lanctot  and Laurent Sifre  and Dharshan Kumaran  and Thore Graepel  and Timothy Lillicrap  and Karen Simonyan  and Demis Hassabis },
  title={A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
  journal={Science},
  year={2018},
  url={https://www.science.org/doi/abs/10.1126/science.aar6404},
}


@article{mcts-survey:2012,
  author={Browne, Cameron B. and Powley, Edward and Whitehouse, Daniel and Lucas, Simon M. and Cowling, Peter I. and Rohlfshagen, Philipp and Tavener, Stephen and Perez, Diego and Samothrakis, Spyridon and Colton, Simon},
  journal={IEEE Transactions on Computational Intelligence and AI in Games}, 
  title={A Survey of Monte Carlo Tree Search Methods}, 
  year={2012},
  doi={10.1109/TCIAIG.2012.2186810}
}
