\newcommand{\white}{\fullmoon}
\newcommand{\black}{\newmoon}

\newcommand{\bigtimes}{\mathop{\raisebox{-0.5ex}{\scalebox{2}{$\times$}}}}

% https://texdoc.org/serve/chessboard/0
\newcounter{pieceindex}
\newcommand{\pieceBoard}{
    \newcount\pieceindex
    \setcounter{pieceindex}{0}
    \raisebox{-7ex}{
        \centering
        \chessboard[
            tinyboard,
            showmover=false,
            margin=false,
            padding=false,
            hlabel=false,
            vlabel=false,
            pgfstyle={text},
            %text=\fontsize{1.2ex}{1.2ex}\bfseries\sffamily \thepieceindex \stepcounter{pieceindex}, %  \currentwq
            text=\fontsize{1.2ex}{1.2ex}\bfseries\sffamily \currentwq,
            markboard
        ]
    }
}
\newcommand{\pieceRolesTable}{
    \begin{tabular}{|l|}
        \hline
        \sympawn\ Pawn \\
        \hline
        \symknight\ Knight \\
        \hline
        \symbishop\ Bishop \\
        \hline
        \symrook\ Rook \\
        \hline
        \symqueen\ Queen \\
        \hline
        \symking\ King \\
        \hline
    \end{tabular}
}
\newcommand{\pieceColorsTable}{
    \begin{tabular}{|l|}
        \hline
        $\white$ White \\
        \hline
        $\black$ Black \\
        \hline
    \end{tabular}
}

\newcommand{\fs}[1]{\textsc{#1}}


\section{Feature set (board encoding)}

To evaluate chess positions, we will use a neural network with an architecture explained in detail in the next chapter. In this chapter, we will build the one-dimensional input vector for such network, which can be described entirely by a feature set.

A feature set is a set built by a cartesian product of smaller sets of features, where each set extracts a different aspect of a position. Each tuple in the feature set corresponds to an element in the input vector, which will be set to $1$ if the aspects captured by the tuple is present in the position, and $0$ otherwise. If a tuple is present in a position, we say that the tuple is \textit{active}.

Let's consider some basic sets of features. The following sets encode positional information about the board:

\begin{center}
\begin{tabular}{cc}

$\begin{aligned}[t]
\fs{File} &= \{a, b, ..., h\} \\
\fs{Rank} &= \{1, 2, ..., 8\} \\
\fs{Square} &= \{a1, a2, ..., h8\}
\end{aligned}$

&

\raisebox{-10ex}{
\chessboard[
    tinyboard,
    showmover=false,
    pgfstyle={text},
    %text=\fontsize{1.2ex}{1.2ex}\bfseries\sffamily \thepieceindex \stepcounter{pieceindex}, %  \currentwq
    text=\fontsize{1.2ex}{1.2ex}\bfseries\sffamily \currentwq,
    markboard
]
}

\end{tabular}
\end{center}

And the following encode information about the pieces:

\begin{center}
$\begin{aligned}[t]
\fs{Role} &= \text{\{
    \sympawn\ Pawn,
    \symknight\ Knight,
    \symbishop\ Bishop,
    \symrook\ Rook,
    \symqueen\ Queen,
    \symking\ King\}}\textsuperscript{1} \\
\fs{Color} &= \text{\{\white\ White, \black\ Black\}}
\end{aligned}$
\end{center}

Since each set has to capture some information from the position, it must be stated explicitly. For example, consider the feature set $\fs{File}_{P} \times \fs{Color}_{P}$ where $P$ is \textit{any} piece in the board, meaning that the tuples $(file, color)$ that will be active are the ones where there is at least one piece in $file$ with the color $color$ (disregarding any other kind of information, like the piece's role). Another possible feature set could be $\fs{File}_{P} \times \fs{Role}_{P}$, with a similar interpretation. An illustration of the active features of these two feature sets for the same board is shown in Figure \ref{fig:active_features}.

\begin{figure}[h]
\centering
\label{fig:active_features}

\begin{tabular}{cc}
\raisebox{-7ex}{
\chessboard[
    tinyboard,
    showmover=false,
    hlabel=false,
    setwhite={kc3, nc2, pa2, Pd4},
    addblack={Kc8,bh7, pa7}
]
}

&

\begin{tabular}{|c|p{4cm}|p{4cm}|p{0cm}}
\cline{2-3}
\multicolumn{1}{c|}{} & \multicolumn{2}{c|}{\centering Feature set} \\
\cline{2-3}
\multicolumn{1}{c|}{} & \centering $\fs{File}_{P} \times \fs{Color}_{P}$ & \centering $\fs{File}_{P} \times \fs{Role}_{P}$ & \\
\cline{1-3}
Active features &
(a, \white), (a, \black), (c, \black), (c, \white), (d, \white), (h, \black) &
(a, \sympawn), (c, \symking), (c, \symknight), (d, \sympawn), (h, \symbishop) \\
\cline{1-3}
\end{tabular}

\end{tabular}

\caption{Active features of the feature sets $\fs{File}_{P} \times \fs{Color}_{P}$ and $\fs{File}_{P} \times \fs{Role}_{P}$ for the same board}
\end{figure}

\footnotetext[1]{The color of the pieces have no meaning in the definition. They are present for illustrative purposes.}

\subsection{Sum $\oplus$}

% what to talk about:
% we want the network to find patterns between the two sets
% some feature sets can be built merging the features of two or more sets

The sum of two feature sets $\fs{A}$ and $\fs{B}$, denoted by $\fs{A} \oplus \fs{B}$, is a new feature set comprised of the tuples of both sets $\fs{A}$ and $\fs{B}$. These tuples do not interfere with each other, even if they have the same basic elements (e.g. h, 8, \symrook, \black), they \textbf{must} have different interpretations.
For example, given the feature sets $\fs{File}_{W}$ where $W$ is any white piece in the board and $\fs{File}_{B}$ where $B$ is any black piece in the board, the feature set $\fs{File}_{W} \oplus \fs{File}_{B}$ will have the basic elements $\{a, b, ..., h\}$ for both white and black pieces, but each with a different interpretation.

The sum operator is useful when we want to let the network find patterns combining information between two sets of features.



\subsection{Indexing}

The input to the network is a one-dimensional vector, so we need a way to map the tuples in a feature set to the elements in the input vector. The correct index for a tuple is computed using the order of the sets in the cartesian product and the size of each set, like strides in a multi-dimensional array. For this to work, each element in a set $S$ must correspond to a number between $0$ and $|S| - 1$. For example, the feature set $A \times B \times C$ has $|A| \times |B| \times |C|$ elements, and the tuple $(a, b, c)$ is mapped to the element indexed at $a \times |B| \times |C| + b \times |C| + c$.

The same striding logic applies to feature sets built with the sum operator, recursively. [example?]

\subsection{Feature sets}

In this section, we will define the feature sets that will be used in the experiments. We will start with some of the most basic yet reasonable feature sets, then move to feature sets that are used by engines or were used in the past, and finally some that have not been tried, to the best of our knowledge.

\subsubsection{\mdseries\fs{Piece}}

This feature set is the most natural encoding for a chess position. There is a one-to-one mapping between pieces in the board and features:

\begin{center}
    $\fs{Piece} = \fs{Square}_{P} \times \fs{Role}_{P} \times \fs{Color}_{P}$ \\
    for every $P$ piece in the board \\
    ~\\
    $64*6*2=768$ features
\end{center}

For every position, role and color each piece could be, there is a feature. There are 16 tuples in the set that will never be active: (a8..h8, \sympawn, \white) and (a1..h1, \sympawn, \black) that correspond to the white pawns in the last rank and the black pawns in the first rank. This is because pawns promote to another piece when they reach the opponent side of the board. Effectively, these will be dead neurons in the network, but this way we can keep the indexing straightforward. Most feature sets will have dead features, and the same logic applies.

\subsubsection{\mdseries\fs{Compact}}

This is a very compact feature set that still retains all the information of the board, meaning everything can be reconstructed by the neural network:

\begin{center}
    $\fs{Compact} = (\fs{File}_{P} \times \fs{Role}_{P} \times \fs{Color}_{P}) \oplus (\fs{Rank}_{P} \times \fs{Role}_{P} \times \fs{Color}_{P})$ \\
    for every $P$ piece in the board \\
\end{center}

The $\fs{Compact}$ feature set has $2*(8*6*2)=192$ features.

\subsubsection{\mdseries\fs{King-Piece}}

$\fs{King-Piece} = \fs{Square}_{K} \times \fs{Piece}_{P}$ where $K$ is the king to move and $P$ is any \textit{non-king} piece

$\langle side\_king\_square, piece\_square, piece\_type, piece\_color \rangle$ excl. king

$64*64*5*2=40960$ features

There are variations to this feature set, such as \fs{HalfKAv2} or notably \fs{HalfKAv2\_hm} that is currently the latest feature set used by Stockfish 16.1. I will not consider them in this work.

known as "KP" in the literature

if we skip the king, you may be thinking where does it get the information about the other king's side, .... blabla arquitectura Half

\subsubsection{\mdseries\fs{Piece+Moves}}

This feature set comes up from seeing the patterns recognized by the Piece feature set in section 5.5.5. When we observe... attack patterns...:
P..

\fs{HalfP} $\oplus \langle move\_from, move\_to \rangle$

$768 + 64*64=4864$ features

Not friendly to efficiently update the network. It is almost always better to do a full refresh on eval.


\subsubsection{\mdseries\fs{Half-Relative(H$|$V$|$HV)King-Piece}}


$\langle side\_king\_file - piece\_file + 7, side\_king\_rank - piece\_rank + 7, piece\_type, piece\_color \rangle$ excl. king

$15*15*5*2=2250$ features (for HV)

only H or only V have $8*15*5*2=1200$ features


\subsubsection{\mdseries\fs{Half-Top(PP)}}

Statistical feature set, blabla, wasted features blabla


\subsection{Summary}

\begin{table}[h]
\centering
\begin{tabular}{|l|c|c|c|c|}
\hline
Feature set & Tuple & \# features \\
\hline
\fs{Piece} & $\fs{Square}_{P} \times \fs{Role}_{P} \times \fs{Color}_{P}$ & 768  \\
\fs{Compact} & asd & 192  \\
\fs{Piece+Moves} & asd & 4864 \\
\fs{King-Piece} & asd & 40,960 \\
\fs{RelativeHV-King-Piece} & asd & 2250  \\
\fs{TopPP} & asd & 64  \\
\hline
\end{tabular}
\caption{Comparison of feature sets}
\end{table}
