\newcommand{\white}{\fullmoon}
\newcommand{\black}{\newmoon}

\newcommand{\bigtimes}{\mathop{\raisebox{-0.5ex}{\scalebox{2}{$\times$}}}}

% https://texdoc.org/serve/chessboard/0
\newcounter{pieceindex}
\newcommand{\pieceBoard}{
    \newcount\pieceindex
    \setcounter{pieceindex}{0}
    \raisebox{-7ex}{
        \centering
        \chessboard[
            tinyboard,
            showmover=false,
            margin=false,
            padding=false,
            hlabel=false,
            vlabel=false,
            pgfstyle={text},
            %text=\fontsize{1.2ex}{1.2ex}\bfseries\sffamily \thepieceindex \stepcounter{pieceindex}, %  \currentwq
            text=\fontsize{1.2ex}{1.2ex}\bfseries\sffamily \currentwq,
            markboard
        ]
    }
}
\newcommand{\pieceRolesTable}{
    \begin{tabular}{|l|}
        \hline
        \sympawn\ Pawn \\
        \hline
        \symknight\ Knight \\
        \hline
        \symbishop\ Bishop \\
        \hline
        \symrook\ Rook \\
        \hline
        \symqueen\ Queen \\
        \hline
        \symking\ King \\
        \hline
    \end{tabular}
}
\newcommand{\pieceColorsTable}{
    \begin{tabular}{|l|}
        \hline
        $\white$ White \\
        \hline
        $\black$ Black \\
        \hline
    \end{tabular}
}

\newcommand{\featureset}[1]{\textsc{#1}}


\section{Feature sets (board encodings)}

To evaluate chess positions, the engine will use a neural network with an architecture explained in detail in the next chapter. In this chapter, I will show how to build the one-dimensional input vector for such network, which can be described entirely by a feature set.

A feature set (or feature block) is comprised of elements which represent some information about a chess position. A feature set is usually built by a cartesian product of smaller sets of features, to represent more complex patterns. Each element corresponds to a value in the input vector, which will be set to $1$ if the pattern captured by the element is present in the position (we say that the element is \textit{active}), and $0$ otherwise.

Let's consider some basic sets of features. The following sets encode positional information about the board:

\begin{center}
\begin{tabular}{cc}

$\begin{aligned}[t]
\featureset{File} &= \{a, b, ..., h\} \\
\featureset{Rank} &= \{1, 2, ..., 8\} \\
\featureset{Square} &= \{a1, a2, ..., h8\}
\end{aligned}$

&

\raisebox{-10ex}{
\chessboard[
    tinyboard,
    showmover=false,
    pgfstyle={text},
    %text=\fontsize{1.2ex}{1.2ex}\bfseries\sffamily \thepieceindex \stepcounter{pieceindex}, %  \currentwq
    text=\fontsize{1.2ex}{1.2ex}\bfseries\sffamily \currentwq,
    markboard
]
}

\end{tabular}
\end{center}

And the following encode information about the pieces:

\begin{center}
$\begin{aligned}[t]
\featureset{Role} &= \text{\{
    \sympawn\ Pawn,
    \symknight\ Knight,
    \symbishop\ Bishop,
    \symrook\ Rook,
    \symqueen\ Queen,
    \symking\ King\}}\textsuperscript{1} \\
\featureset{Color} &= \text{\{\white\ White, \black\ Black\}}
\end{aligned}$
\end{center}

\footnotetext[1]{The color of the pieces have no meaning in the definition. They are present for illustrative purposes.}

Since each set has to capture some pattern from the position, it must be stated explicitly. For example, consider the feature set $\featureset{File}_{P} \times \featureset{Color}_{P}$ where $P$ is \textit{any} piece in the board, meaning that the tuples $(file, color)$ that will be active are the ones where there is at least one piece in $file$ with the color $color$ (disregarding any other kind of information, like the piece's role). Another possible feature set could be $\featureset{File}_{P} \times \featureset{Role}_{P}$, with a similar interpretation. Note that $\featureset{Square}_Q = \featureset{File}_Q \times \featureset{Rank}_Q$ $\forall Q$. An illustration of the active features of these two feature sets for the same board is shown in Figure \ref{fig:active_features}.

\begin{figure}[H]
\centering

\begin{tabular}{cc}
\raisebox{-7ex}{
\chessboard[
    tinyboard,
    showmover=false,
    hlabel=false,
    setwhite={kc3, nc2, pa2, Pd4},
    addblack={Kc8,bh7, pa7}
]
}

&

\begin{tabular}{|c|p{4cm}|p{4cm}|p{0cm}}
\cline{2-3}
\multicolumn{1}{c|}{} & \multicolumn{2}{c|}{\centering Feature set} \\
\cline{2-3}
\multicolumn{1}{c|}{} & \centering $\featureset{File}_{P} \times \featureset{Color}_{P}$ & \centering $\featureset{File}_{P} \times \featureset{Role}_{P}$ & \\
\cline{1-3}
Active features &
(a, \white), (a, \black), (c, \black), (c, \white), (d, \white), (h, \black) &
(a, \sympawn), (c, \symking), (c, \symknight), (d, \sympawn), (h, \symbishop) \\
\cline{1-3}
\end{tabular}

\end{tabular}

\caption{Active features of the feature sets $\featureset{File}_{P} \times \featureset{Color}_{P}$ and $\featureset{File}_{P} \times \featureset{Role}_{P}$ for the same board.}
\label{fig:active_features}
\end{figure}


\subsection{Sum $\oplus$}

% what to talk about:
% we want the network to find patterns between the two sets
% some feature sets can be built merging the features of two or more sets

The sum (or concatenation) of two feature sets (often called blocks) $\featureset{A}$ and $\featureset{B}$, denoted by $\featureset{A} \oplus \featureset{B}$, is a new feature set comprised of the elements of both sets $\featureset{A}$ and $\featureset{B}$. These elements do not interfere with each other, even if they share basic elements (e.g. h, 8, \symrook, \black), they \textbf{must} have different interpretations.
For example, given the feature sets $\featureset{File}_{W}$ where $W$ is any white piece in the board and $\featureset{File}_{B}$ where $B$ is any black piece in the board, the feature set $\featureset{File}_{W} \oplus \featureset{File}_{B}$ will have the basic elements $\{a, b, ..., h\}$ for both white and black pieces, but each with a different interpretation. Note that the notation presented in this work is not standard.

The sum operator is useful when we want to let the network find patterns combining information between two sets of features.

\subsection{Indexing}

The input to the network is a one-dimensional vector, so we need a way to map the tuples (elements are trivial) in a feature set to elements in the input vector. The correct index for a tuple is computed using the order of the sets in the cartesian product and the size of each set, like strides in a multi-dimensional array. For this to work, each element in a set $S$ must correspond to a number between $0$ and $|S| - 1$. For example, the feature set $A \times B \times C$ has $|A| \times |B| \times |C|$ elements, and the tuple $(a, b, c)$ is mapped to the element indexed at $a \times |B| \times |C| + b \times |C| + c$. The same striding logic applies to feature sets built with the sum operator, recursively.

\subsection{Feature sets}

In this section, I will define two of the most important feature sets known and used extensively in existing engines.

\subsubsection{\mdseries\featureset{All}}

This feature set is the most natural encoding for a chess position. It is called \enquote{All} because it captures all the pieces. There is a one-to-one mapping between pieces in the board and features:

\begin{center}
    $\featureset{All} = \featureset{Square}_{P} \times \featureset{Role}_{P} \times \featureset{Color}_{P}$ \\
    for every $P$ piece in the board \\
\end{center}

Tuples in this set are \textit{active} if there is a piece in the board that matches the role, color and position of the tuple. For example, the tuple $(e4, \sympawn, \white)$ is active if there is a white pawn in the square e4. This way, for every possible piece, in every possible position, there is a feature. The set has $64*6*2=$\textbf{ 768 features}, which makes it very small and it is very easy to compute which features are active.

\subsubsection{\mdseries\featureset{King-All}}

Another feature set built on top of $\featureset{All}$ is the \featureset{King-All} feature set, or \enquote{KA} for short. For each possible position of the king of the side to move, it captures all the pieces in the board ($\featureset{All}$):

\begin{center}
    $\featureset{King-All} = \featureset{Square}_{K} \times \featureset{All}_{P}$ \\
    where $K$ is the king of the side to move and\\
    $P$ is every piece in the board \\
\end{center}

This encoding allows the network to understand better the position of the pieces in relation to the king, which is very tied to the evaluation of the position.

The number of features is $64*768=$ \textbf{49152 features}. There is a variation of this feature set called \enquote{KP} which is the same but it does not consider the enemy king, reducing the amount of features to 40960. There are other variations, such as \featureset{KAv2} or notably \featureset{KAv2\_hm} that is currently the latest feature set used by Stockfish 16.1.

The features in this set are easy to compute like in $\featureset{All}$, but since the number of features is much larger, it is a lot harder to train and use in practice. I will restrain this work to smaller feature sets that are easier to manage.

\subsection{Dead features}

Consider the $\featureset{All}$ feature set. For every position, role and color each piece could be, there is a feature. There are 16 tuples in the set that will never be active: (a8..h8, \sympawn, \white) and (a1..h1, \sympawn, \black) that correspond to the white pawns in the last rank and the black pawns in the first rank. This is because pawns promote to another piece when they reach the opponent side of the board, so no pawns will ever be found there. Effectively, these will be dead neurons in the network, but this way we can keep the indexing straightforward. Most feature sets will have dead features, and the same logic applies.
