\section{Introduction}

Chess is a game that has been around for centuries and has been the subject of study in many disciplines. When the first computers started to be developed in the fifties, the interest for computer chess started to grow. Basic chess algorithms were developed, but hardware lacked the power to play a full game. The drastic advancements in software and hardware that followed allowed for the development of what we know today as a \textit{chess engine}: a computer program that analyzes a chess board and provides the strongest move it can find.

Computer chess offers a controlled, yet complex environment to serve as a benchmark to study artificial intelligence, as it requires strategic planning and decision-making under uncertainty, key aspects of AI research.

IBM DeepBlue \cite{deepblue:2002} was the first chess machine to reach superhuman level by consistently beating the world champion, Garry Kasparov, in 1997 \cite{washingtonpost:1997}. Since then, chess engines have evolved in strength and complexity. \\

A chess \text{position} is defined by the state of the game: the position of the pieces on the board, who is to move, castling rights, en passant, 50-move rule, etc. The game of chess can be modeled as a tree, where each node is a particular position and the edges are legal moves for that position. With this representation, chess engines can use tree search algorithms to explore the tree and approximate the best move. Since the 1970s and to this date, chess engines have used algorithms like Minimax \cite{minimax-survey:1995} and Monte Carlo Tree Search \cite{mcts-survey:2012} (MCTS) or some of its variants \cite{tree-search-methods:2014,mcts-modifications:2022} to accomplish this.

The number of possible positions in chess is vast, estimated by Shannon \cite{shannon:1950} to be around $10^{43}$. This number is based on the average number of legal moves per position and the average game length. This makes it not feasible to explore the entire tree, so every tree search algorithm relies on having an evaluation function: a function that takes a position and returns a single real number. This number is used to encompass information about the whole subtree of that position so it can be propagated up the tree, depending on the algorithm. Until a few years ago, highly complex handcrafted functions were used that were based on human knowledge about the game. \\

Until the 2010s, the development of chess engines advanced at a slow but consistent pace. Until 2017 that Google DeepMind published AlphaGo Zero \cite{alphagozero:2017} and its successor AlphaZero \cite{alphazero:2017,alphazero:2018} in 2018, which proved to be overwhelmingly superior (28 wins, 73 draws, and 0 losses against the best chess engine at that time). They introduced a new approach to the development of board game engines, including chess: train a convolutional neural network with a reinforcement learning algorithm to learn to play by itself.

This change of paradigm, where the evaluation of positions is done by neural networks instead of functions built with human knowledge, altered the course of development of all modern engines (not just Go and chess). In 2018, Yu Nasu introduced the networks \reflectbox{EUNN} (or NNUE) ``Efficiently Updatable Neural-Networks'' \cite{nnue:2018} for the game Shogi. NNUE networks allow for cheap evaluations when evaluating a sequence of similar positions, making them ideal for use in depth-first search-based engines. Since then, all modern chess engines have incorporated NNUE networks or some kind of neural network in their evaluation.

The chess engine Stockfish \cite{stockfish}, modern successor of DeepBlue with improved heuristics and running in commercial hardware, is one of the strongest in the world. It incorporated NNUE networks mixed with classical evaluation in version 12\footnote[1]{\href{https://stockfishchess.org/blog/2020/introducing-nnue-evaluation/}{Introducing NNUE evaluation (Stockfish 12)}}. Since Stockfish 16.1\footnote[2]{\href{https://stockfishchess.org/blog/2024/stockfish-16-1/}{Removal of handcrafted evaluation (Stockfish 16.1)}} (2024) the evaluation is done exclusively through NNUE networks, eliminating all human aspects. \\

The input to an NNUE network is a one-dimensional vector of one-hot features. Each feature represents a well defined aspect of the position, like the position of pieces. A collection of features is called a \textit{feature set}, and can be defined formally. The term \textit{encoding} is used to refer to feature sets as well, as they encode the board state into a vector. \\

The main goal of this thesis is to propose and evaluate multiple feature sets in an attempt to improve well-known ones. Additionally, an alternative approach to train NNUE networks is tried, where the training data comes from observed moves and not evaluations.

In order to carry out this work, a chess engine is required that supports neural networks with the ability to customize the features and a way to train them. I decided to implement a simple but capable classic chess engine based on well-known algorithms and optimizations. Then change the evaluation to use NNUE networks with a versatile framework to build feature sets. Finally, I implemented a training pipeline to train the networks and measure their performance.

\subsection{Source code}

The source code for this work can be found online in the following repositories:

\begin{table}[H]
\centering
\begin{tabular}{ll}
\toprule
\textbf{Repository} & \textbf{Repository} \\
\midrule
Source code & \url{https://github.com/mlomb/cs-master-thesis} \\
\LaTeX\ documents & \url{https://github.com/mlomb/cs-master-thesis-doc}
\end{tabular}
\end{table}
